{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение датасетов\n",
    "mylist= os.listdir('RawData/')\n",
    "\n",
    "#Список эмоций\n",
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')\n",
    "        \n",
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделение признаков\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('RawData/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование\n",
    "df3 = pd.DataFrame(df['feature'].values.tolist())\n",
    "newdf = pd.concat([df3,labels], axis=1)\n",
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pepega\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Разделение на тестовые и тренировочные данные\n",
    "newdf1 = np.random.rand(len(rnewdf)) < 0.7\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabel = train.iloc[:, -1:]\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabel = test.iloc[:, -1:]\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание модели\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "46/46 [==============================] - 5s 85ms/step - loss: 2.5347 - accuracy: 0.0975 - val_loss: 2.3010 - val_accuracy: 0.0966\n",
      "Epoch 2/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.3623 - accuracy: 0.1258 - val_loss: 2.2756 - val_accuracy: 0.1212\n",
      "Epoch 3/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.3406 - accuracy: 0.1174 - val_loss: 2.2577 - val_accuracy: 0.1166\n",
      "Epoch 4/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 2.2854 - accuracy: 0.1246 - val_loss: 2.2411 - val_accuracy: 0.1258\n",
      "Epoch 5/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.2622 - accuracy: 0.1573 - val_loss: 2.2246 - val_accuracy: 0.1472\n",
      "Epoch 6/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 2.2587 - accuracy: 0.1439 - val_loss: 2.2101 - val_accuracy: 0.2055\n",
      "Epoch 7/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 2.2262 - accuracy: 0.1534 - val_loss: 2.1995 - val_accuracy: 0.2025\n",
      "Epoch 8/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.2121 - accuracy: 0.1562 - val_loss: 2.1829 - val_accuracy: 0.2147\n",
      "Epoch 9/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.1906 - accuracy: 0.1808 - val_loss: 2.1668 - val_accuracy: 0.2377\n",
      "Epoch 10/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.1799 - accuracy: 0.2051 - val_loss: 2.1528 - val_accuracy: 0.2147\n",
      "Epoch 11/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 2.1721 - accuracy: 0.1898 - val_loss: 2.1312 - val_accuracy: 0.2377\n",
      "Epoch 12/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 2.1517 - accuracy: 0.1837 - val_loss: 2.1165 - val_accuracy: 0.2485\n",
      "Epoch 13/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.1084 - accuracy: 0.2263 - val_loss: 2.0935 - val_accuracy: 0.2393\n",
      "Epoch 14/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.1139 - accuracy: 0.2038 - val_loss: 2.0843 - val_accuracy: 0.2347\n",
      "Epoch 15/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.0815 - accuracy: 0.2059 - val_loss: 2.0543 - val_accuracy: 0.2439\n",
      "Epoch 16/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 2.0564 - accuracy: 0.2280 - val_loss: 2.0348 - val_accuracy: 0.2791\n",
      "Epoch 17/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 2.0412 - accuracy: 0.2120 - val_loss: 2.0141 - val_accuracy: 0.2531\n",
      "Epoch 18/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 2.0058 - accuracy: 0.2412 - val_loss: 1.9944 - val_accuracy: 0.2699\n",
      "Epoch 19/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.9861 - accuracy: 0.2323 - val_loss: 1.9740 - val_accuracy: 0.2730\n",
      "Epoch 20/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.9701 - accuracy: 0.2692 - val_loss: 1.9481 - val_accuracy: 0.2837\n",
      "Epoch 21/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.9456 - accuracy: 0.2501 - val_loss: 1.9313 - val_accuracy: 0.2699\n",
      "Epoch 22/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.9211 - accuracy: 0.2654 - val_loss: 1.9128 - val_accuracy: 0.2883\n",
      "Epoch 23/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.9276 - accuracy: 0.2670 - val_loss: 1.8958 - val_accuracy: 0.2975\n",
      "Epoch 24/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.8780 - accuracy: 0.2835 - val_loss: 1.8730 - val_accuracy: 0.2975\n",
      "Epoch 25/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.8783 - accuracy: 0.2730 - val_loss: 1.8498 - val_accuracy: 0.3129\n",
      "Epoch 26/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.8513 - accuracy: 0.2829 - val_loss: 1.8326 - val_accuracy: 0.3160\n",
      "Epoch 27/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.8421 - accuracy: 0.2870 - val_loss: 1.8327 - val_accuracy: 0.2822\n",
      "Epoch 28/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.7866 - accuracy: 0.3137 - val_loss: 1.8025 - val_accuracy: 0.3298\n",
      "Epoch 29/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.7657 - accuracy: 0.3237 - val_loss: 1.7807 - val_accuracy: 0.3558\n",
      "Epoch 30/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.7576 - accuracy: 0.3082 - val_loss: 1.7650 - val_accuracy: 0.3313\n",
      "Epoch 31/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.7473 - accuracy: 0.3069 - val_loss: 1.7802 - val_accuracy: 0.3282\n",
      "Epoch 32/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.7149 - accuracy: 0.3346 - val_loss: 1.7372 - val_accuracy: 0.3313\n",
      "Epoch 33/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.7200 - accuracy: 0.3144 - val_loss: 1.7256 - val_accuracy: 0.3482\n",
      "Epoch 34/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.7086 - accuracy: 0.3329 - val_loss: 1.7188 - val_accuracy: 0.3359\n",
      "Epoch 35/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.6828 - accuracy: 0.3512 - val_loss: 1.7074 - val_accuracy: 0.3512\n",
      "Epoch 36/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.6612 - accuracy: 0.3568 - val_loss: 1.6999 - val_accuracy: 0.3190\n",
      "Epoch 37/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.6682 - accuracy: 0.3402 - val_loss: 1.6959 - val_accuracy: 0.3374\n",
      "Epoch 38/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.6609 - accuracy: 0.3568 - val_loss: 1.7173 - val_accuracy: 0.3175\n",
      "Epoch 39/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.6548 - accuracy: 0.3583 - val_loss: 1.6738 - val_accuracy: 0.3420\n",
      "Epoch 40/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.6345 - accuracy: 0.3728 - val_loss: 1.6674 - val_accuracy: 0.3374\n",
      "Epoch 41/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.6340 - accuracy: 0.3645 - val_loss: 1.6579 - val_accuracy: 0.3420\n",
      "Epoch 42/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.6208 - accuracy: 0.3597 - val_loss: 1.6510 - val_accuracy: 0.3359\n",
      "Epoch 43/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.6237 - accuracy: 0.3632 - val_loss: 1.6498 - val_accuracy: 0.3420\n",
      "Epoch 44/750\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 1.5905 - accuracy: 0.3786 - val_loss: 1.6332 - val_accuracy: 0.3696\n",
      "Epoch 45/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.6155 - accuracy: 0.3671 - val_loss: 1.6409 - val_accuracy: 0.3267\n",
      "Epoch 46/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.5982 - accuracy: 0.3652 - val_loss: 1.6281 - val_accuracy: 0.3482\n",
      "Epoch 47/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.5812 - accuracy: 0.3555 - val_loss: 1.6257 - val_accuracy: 0.3528\n",
      "Epoch 48/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.5612 - accuracy: 0.3704 - val_loss: 1.6155 - val_accuracy: 0.3436\n",
      "Epoch 49/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.5423 - accuracy: 0.3970 - val_loss: 1.6047 - val_accuracy: 0.3635\n",
      "Epoch 50/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.5617 - accuracy: 0.4091 - val_loss: 1.6047 - val_accuracy: 0.3451\n",
      "Epoch 51/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.5457 - accuracy: 0.3792 - val_loss: 1.5994 - val_accuracy: 0.3497\n",
      "Epoch 52/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.5725 - accuracy: 0.3545 - val_loss: 1.6152 - val_accuracy: 0.3497\n",
      "Epoch 53/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.5274 - accuracy: 0.3939 - val_loss: 1.5926 - val_accuracy: 0.3390\n",
      "Epoch 54/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.5163 - accuracy: 0.4202 - val_loss: 1.5902 - val_accuracy: 0.3558\n",
      "Epoch 55/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.5048 - accuracy: 0.4029 - val_loss: 1.5904 - val_accuracy: 0.3589\n",
      "Epoch 56/750\n",
      "46/46 [==============================] - 4s 80ms/step - loss: 1.5672 - accuracy: 0.3936 - val_loss: 1.5846 - val_accuracy: 0.3620\n",
      "Epoch 57/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 1.4823 - accuracy: 0.3905 - val_loss: 1.5784 - val_accuracy: 0.3574\n",
      "Epoch 58/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 1.5135 - accuracy: 0.3988 - val_loss: 1.6159 - val_accuracy: 0.3436\n",
      "Epoch 59/750\n",
      "46/46 [==============================] - 4s 78ms/step - loss: 1.4730 - accuracy: 0.4192 - val_loss: 1.5709 - val_accuracy: 0.3696\n",
      "Epoch 60/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 1.5032 - accuracy: 0.4096 - val_loss: 1.5667 - val_accuracy: 0.3727\n",
      "Epoch 61/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 1.4914 - accuracy: 0.4204 - val_loss: 1.5690 - val_accuracy: 0.3742\n",
      "Epoch 62/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.4950 - accuracy: 0.3998 - val_loss: 1.5625 - val_accuracy: 0.3574\n",
      "Epoch 63/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.4915 - accuracy: 0.4308 - val_loss: 1.5560 - val_accuracy: 0.3742\n",
      "Epoch 64/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4903 - accuracy: 0.4181 - val_loss: 1.5572 - val_accuracy: 0.3681\n",
      "Epoch 65/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.4906 - accuracy: 0.4047 - val_loss: 1.5583 - val_accuracy: 0.3620\n",
      "Epoch 66/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.4118 - accuracy: 0.4177 - val_loss: 1.5650 - val_accuracy: 0.3574\n",
      "Epoch 67/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.4266 - accuracy: 0.4358 - val_loss: 1.5539 - val_accuracy: 0.3758\n",
      "Epoch 68/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.4661 - accuracy: 0.4226 - val_loss: 1.5448 - val_accuracy: 0.3742\n",
      "Epoch 69/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.4252 - accuracy: 0.4534 - val_loss: 1.5405 - val_accuracy: 0.3896\n",
      "Epoch 70/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.4183 - accuracy: 0.4516 - val_loss: 1.5514 - val_accuracy: 0.3727\n",
      "Epoch 71/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.4343 - accuracy: 0.4281 - val_loss: 1.5448 - val_accuracy: 0.3650\n",
      "Epoch 72/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.4471 - accuracy: 0.4397 - val_loss: 1.5363 - val_accuracy: 0.3712\n",
      "Epoch 73/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4348 - accuracy: 0.4402 - val_loss: 1.5248 - val_accuracy: 0.3896\n",
      "Epoch 74/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.4394 - accuracy: 0.4207 - val_loss: 1.5526 - val_accuracy: 0.3497\n",
      "Epoch 75/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4582 - accuracy: 0.4101 - val_loss: 1.5444 - val_accuracy: 0.3681\n",
      "Epoch 76/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.4442 - accuracy: 0.4270 - val_loss: 1.5491 - val_accuracy: 0.3742\n",
      "Epoch 77/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.3918 - accuracy: 0.4397 - val_loss: 1.5567 - val_accuracy: 0.3896\n",
      "Epoch 78/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4222 - accuracy: 0.4726 - val_loss: 1.5253 - val_accuracy: 0.3666\n",
      "Epoch 79/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.4261 - accuracy: 0.4396 - val_loss: 1.5350 - val_accuracy: 0.3850\n",
      "Epoch 80/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4111 - accuracy: 0.4461 - val_loss: 1.5271 - val_accuracy: 0.3880\n",
      "Epoch 81/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3930 - accuracy: 0.4567 - val_loss: 1.5162 - val_accuracy: 0.3880\n",
      "Epoch 82/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.3910 - accuracy: 0.4366 - val_loss: 1.5139 - val_accuracy: 0.3834\n",
      "Epoch 83/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3671 - accuracy: 0.4557 - val_loss: 1.5069 - val_accuracy: 0.3911\n",
      "Epoch 84/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.4037 - accuracy: 0.4549 - val_loss: 1.5177 - val_accuracy: 0.3727\n",
      "Epoch 85/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3662 - accuracy: 0.4485 - val_loss: 1.5146 - val_accuracy: 0.3865\n",
      "Epoch 86/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.3537 - accuracy: 0.4780 - val_loss: 1.5034 - val_accuracy: 0.3972\n",
      "Epoch 87/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.3828 - accuracy: 0.4772 - val_loss: 1.5154 - val_accuracy: 0.3804\n",
      "Epoch 88/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.3594 - accuracy: 0.4964 - val_loss: 1.5079 - val_accuracy: 0.3819\n",
      "Epoch 89/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3935 - accuracy: 0.4325 - val_loss: 1.5135 - val_accuracy: 0.3834\n",
      "Epoch 90/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3589 - accuracy: 0.4777 - val_loss: 1.4990 - val_accuracy: 0.3926\n",
      "Epoch 91/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3365 - accuracy: 0.4643 - val_loss: 1.5094 - val_accuracy: 0.3880\n",
      "Epoch 92/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3636 - accuracy: 0.4751 - val_loss: 1.5285 - val_accuracy: 0.3880\n",
      "Epoch 93/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.3673 - accuracy: 0.4565 - val_loss: 1.4908 - val_accuracy: 0.4034\n",
      "Epoch 94/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3400 - accuracy: 0.4742 - val_loss: 1.5007 - val_accuracy: 0.3819\n",
      "Epoch 95/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.3448 - accuracy: 0.4591 - val_loss: 1.4911 - val_accuracy: 0.3957\n",
      "Epoch 96/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.3392 - accuracy: 0.4916 - val_loss: 1.4931 - val_accuracy: 0.3850\n",
      "Epoch 97/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.3404 - accuracy: 0.4821 - val_loss: 1.4971 - val_accuracy: 0.3926\n",
      "Epoch 98/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.3663 - accuracy: 0.4645 - val_loss: 1.4936 - val_accuracy: 0.3804\n",
      "Epoch 99/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.3744 - accuracy: 0.4428 - val_loss: 1.5024 - val_accuracy: 0.3896\n",
      "Epoch 100/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3326 - accuracy: 0.4751 - val_loss: 1.5307 - val_accuracy: 0.3834\n",
      "Epoch 101/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.3434 - accuracy: 0.4816 - val_loss: 1.4921 - val_accuracy: 0.4034\n",
      "Epoch 102/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3500 - accuracy: 0.4572 - val_loss: 1.4928 - val_accuracy: 0.3926\n",
      "Epoch 103/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.3632 - accuracy: 0.4781 - val_loss: 1.4890 - val_accuracy: 0.3972\n",
      "Epoch 104/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.3395 - accuracy: 0.4648 - val_loss: 1.4791 - val_accuracy: 0.4049\n",
      "Epoch 105/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.3164 - accuracy: 0.4983 - val_loss: 1.4816 - val_accuracy: 0.4064\n",
      "Epoch 106/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.3387 - accuracy: 0.4775 - val_loss: 1.4725 - val_accuracy: 0.4156\n",
      "Epoch 107/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.3232 - accuracy: 0.4775 - val_loss: 1.4776 - val_accuracy: 0.4034\n",
      "Epoch 108/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3448 - accuracy: 0.4777 - val_loss: 1.4795 - val_accuracy: 0.4049\n",
      "Epoch 109/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.3276 - accuracy: 0.4939 - val_loss: 1.5005 - val_accuracy: 0.4003\n",
      "Epoch 110/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2954 - accuracy: 0.5012 - val_loss: 1.4748 - val_accuracy: 0.3988\n",
      "Epoch 111/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3046 - accuracy: 0.4840 - val_loss: 1.4771 - val_accuracy: 0.4018\n",
      "Epoch 112/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3336 - accuracy: 0.4593 - val_loss: 1.4750 - val_accuracy: 0.4172\n",
      "Epoch 113/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2931 - accuracy: 0.4839 - val_loss: 1.4721 - val_accuracy: 0.4095\n",
      "Epoch 114/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3102 - accuracy: 0.4908 - val_loss: 1.4680 - val_accuracy: 0.4233\n",
      "Epoch 115/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.2584 - accuracy: 0.4960 - val_loss: 1.5131 - val_accuracy: 0.3942\n",
      "Epoch 116/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.2518 - accuracy: 0.5318 - val_loss: 1.4633 - val_accuracy: 0.4141\n",
      "Epoch 117/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.2725 - accuracy: 0.4957 - val_loss: 1.4599 - val_accuracy: 0.4202\n",
      "Epoch 118/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.3047 - accuracy: 0.4982 - val_loss: 1.4684 - val_accuracy: 0.4141\n",
      "Epoch 119/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2924 - accuracy: 0.5067 - val_loss: 1.4590 - val_accuracy: 0.4110\n",
      "Epoch 120/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.2954 - accuracy: 0.4730 - val_loss: 1.4654 - val_accuracy: 0.4248\n",
      "Epoch 121/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2895 - accuracy: 0.4968 - val_loss: 1.4691 - val_accuracy: 0.4110\n",
      "Epoch 122/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2928 - accuracy: 0.4996 - val_loss: 1.5118 - val_accuracy: 0.3850\n",
      "Epoch 123/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.3079 - accuracy: 0.4881 - val_loss: 1.4481 - val_accuracy: 0.4233\n",
      "Epoch 124/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.2475 - accuracy: 0.5399 - val_loss: 1.4646 - val_accuracy: 0.4156\n",
      "Epoch 125/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2633 - accuracy: 0.5001 - val_loss: 1.4767 - val_accuracy: 0.4049\n",
      "Epoch 126/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.2766 - accuracy: 0.5073 - val_loss: 1.4674 - val_accuracy: 0.4202\n",
      "Epoch 127/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.2818 - accuracy: 0.5150 - val_loss: 1.4525 - val_accuracy: 0.4218\n",
      "Epoch 128/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.2743 - accuracy: 0.5015 - val_loss: 1.4610 - val_accuracy: 0.4156\n",
      "Epoch 129/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.2682 - accuracy: 0.4984 - val_loss: 1.4536 - val_accuracy: 0.4233\n",
      "Epoch 130/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.2847 - accuracy: 0.4963 - val_loss: 1.4684 - val_accuracy: 0.4248\n",
      "Epoch 131/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.2274 - accuracy: 0.5002 - val_loss: 1.4568 - val_accuracy: 0.4279\n",
      "Epoch 132/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2580 - accuracy: 0.5255 - val_loss: 1.4466 - val_accuracy: 0.4248\n",
      "Epoch 133/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2644 - accuracy: 0.4993 - val_loss: 1.4545 - val_accuracy: 0.4279\n",
      "Epoch 134/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.2966 - accuracy: 0.4759 - val_loss: 1.4609 - val_accuracy: 0.4049\n",
      "Epoch 135/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2275 - accuracy: 0.5173 - val_loss: 1.4655 - val_accuracy: 0.4202\n",
      "Epoch 136/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.2119 - accuracy: 0.5492 - val_loss: 1.4550 - val_accuracy: 0.4095\n",
      "Epoch 137/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.2142 - accuracy: 0.5346 - val_loss: 1.4663 - val_accuracy: 0.4172\n",
      "Epoch 138/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1887 - accuracy: 0.5230 - val_loss: 1.4438 - val_accuracy: 0.4279\n",
      "Epoch 139/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2455 - accuracy: 0.5254 - val_loss: 1.4894 - val_accuracy: 0.4126\n",
      "Epoch 140/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2189 - accuracy: 0.5476 - val_loss: 1.4474 - val_accuracy: 0.4340\n",
      "Epoch 141/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.2182 - accuracy: 0.5341 - val_loss: 1.4462 - val_accuracy: 0.4294\n",
      "Epoch 142/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.2240 - accuracy: 0.5087 - val_loss: 1.4494 - val_accuracy: 0.4187\n",
      "Epoch 143/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2559 - accuracy: 0.5064 - val_loss: 1.4531 - val_accuracy: 0.4126\n",
      "Epoch 144/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2117 - accuracy: 0.5354 - val_loss: 1.4647 - val_accuracy: 0.4049\n",
      "Epoch 145/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.2179 - accuracy: 0.5143 - val_loss: 1.4360 - val_accuracy: 0.4402\n",
      "Epoch 146/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.1995 - accuracy: 0.5543 - val_loss: 1.4507 - val_accuracy: 0.4279\n",
      "Epoch 147/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 1.1971 - accuracy: 0.5187 - val_loss: 1.4462 - val_accuracy: 0.4233\n",
      "Epoch 148/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.2127 - accuracy: 0.5314 - val_loss: 1.4411 - val_accuracy: 0.4310\n",
      "Epoch 149/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.2244 - accuracy: 0.5045 - val_loss: 1.4503 - val_accuracy: 0.4172\n",
      "Epoch 150/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1718 - accuracy: 0.5545 - val_loss: 1.4406 - val_accuracy: 0.4202\n",
      "Epoch 151/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2200 - accuracy: 0.5164 - val_loss: 1.4374 - val_accuracy: 0.4387\n",
      "Epoch 152/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.1809 - accuracy: 0.5414 - val_loss: 1.4513 - val_accuracy: 0.4310\n",
      "Epoch 153/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2119 - accuracy: 0.5470 - val_loss: 1.4515 - val_accuracy: 0.4279\n",
      "Epoch 154/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1766 - accuracy: 0.5448 - val_loss: 1.4361 - val_accuracy: 0.4325\n",
      "Epoch 155/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1743 - accuracy: 0.5718 - val_loss: 1.4300 - val_accuracy: 0.4371\n",
      "Epoch 156/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.1615 - accuracy: 0.5551 - val_loss: 1.4586 - val_accuracy: 0.4248\n",
      "Epoch 157/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.1935 - accuracy: 0.5291 - val_loss: 1.4286 - val_accuracy: 0.4340\n",
      "Epoch 158/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.2021 - accuracy: 0.5261 - val_loss: 1.4345 - val_accuracy: 0.4233\n",
      "Epoch 159/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1936 - accuracy: 0.5635 - val_loss: 1.4284 - val_accuracy: 0.4340\n",
      "Epoch 160/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.2273 - accuracy: 0.5109 - val_loss: 1.4321 - val_accuracy: 0.4371\n",
      "Epoch 161/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1621 - accuracy: 0.5793 - val_loss: 1.4323 - val_accuracy: 0.4340\n",
      "Epoch 162/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2006 - accuracy: 0.5287 - val_loss: 1.4734 - val_accuracy: 0.4248\n",
      "Epoch 163/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1485 - accuracy: 0.5590 - val_loss: 1.4317 - val_accuracy: 0.4340\n",
      "Epoch 164/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1669 - accuracy: 0.5647 - val_loss: 1.4297 - val_accuracy: 0.4325\n",
      "Epoch 165/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1327 - accuracy: 0.5664 - val_loss: 1.4256 - val_accuracy: 0.4433\n",
      "Epoch 166/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.1679 - accuracy: 0.5506 - val_loss: 1.4447 - val_accuracy: 0.4417\n",
      "Epoch 167/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.1550 - accuracy: 0.5574 - val_loss: 1.4182 - val_accuracy: 0.4448\n",
      "Epoch 168/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1485 - accuracy: 0.5398 - val_loss: 1.4318 - val_accuracy: 0.4417\n",
      "Epoch 169/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1749 - accuracy: 0.5565 - val_loss: 1.4207 - val_accuracy: 0.4494\n",
      "Epoch 170/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1458 - accuracy: 0.5678 - val_loss: 1.4181 - val_accuracy: 0.4479\n",
      "Epoch 171/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2019 - accuracy: 0.5502 - val_loss: 1.4340 - val_accuracy: 0.4325\n",
      "Epoch 172/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.2165 - accuracy: 0.5117 - val_loss: 1.4298 - val_accuracy: 0.4387\n",
      "Epoch 173/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1442 - accuracy: 0.5672 - val_loss: 1.4271 - val_accuracy: 0.4448\n",
      "Epoch 174/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1818 - accuracy: 0.5319 - val_loss: 1.4244 - val_accuracy: 0.4417\n",
      "Epoch 175/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1382 - accuracy: 0.5707 - val_loss: 1.4966 - val_accuracy: 0.4141\n",
      "Epoch 176/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.1816 - accuracy: 0.5302 - val_loss: 1.4327 - val_accuracy: 0.4402\n",
      "Epoch 177/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.1438 - accuracy: 0.5613 - val_loss: 1.4366 - val_accuracy: 0.4356\n",
      "Epoch 178/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.1578 - accuracy: 0.5553 - val_loss: 1.4234 - val_accuracy: 0.4371\n",
      "Epoch 179/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.1462 - accuracy: 0.5578 - val_loss: 1.4182 - val_accuracy: 0.4448\n",
      "Epoch 180/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1475 - accuracy: 0.5652 - val_loss: 1.4238 - val_accuracy: 0.4340\n",
      "Epoch 181/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0996 - accuracy: 0.5740 - val_loss: 1.4303 - val_accuracy: 0.4417\n",
      "Epoch 182/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1485 - accuracy: 0.5488 - val_loss: 1.4355 - val_accuracy: 0.4325\n",
      "Epoch 183/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.1179 - accuracy: 0.5734 - val_loss: 1.4343 - val_accuracy: 0.4325\n",
      "Epoch 184/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1373 - accuracy: 0.5827 - val_loss: 1.4411 - val_accuracy: 0.4371\n",
      "Epoch 185/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1201 - accuracy: 0.5539 - val_loss: 1.4227 - val_accuracy: 0.4479\n",
      "Epoch 186/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1133 - accuracy: 0.5788 - val_loss: 1.4315 - val_accuracy: 0.4463\n",
      "Epoch 187/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.1550 - accuracy: 0.5641 - val_loss: 1.4164 - val_accuracy: 0.4494\n",
      "Epoch 188/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1260 - accuracy: 0.5558 - val_loss: 1.4457 - val_accuracy: 0.4402\n",
      "Epoch 189/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0960 - accuracy: 0.5858 - val_loss: 1.4200 - val_accuracy: 0.4433\n",
      "Epoch 190/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1469 - accuracy: 0.5679 - val_loss: 1.4247 - val_accuracy: 0.4463\n",
      "Epoch 191/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1333 - accuracy: 0.5569 - val_loss: 1.4322 - val_accuracy: 0.4387\n",
      "Epoch 192/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1055 - accuracy: 0.5679 - val_loss: 1.4187 - val_accuracy: 0.4448\n",
      "Epoch 193/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.1026 - accuracy: 0.5815 - val_loss: 1.4229 - val_accuracy: 0.4325\n",
      "Epoch 194/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.1006 - accuracy: 0.5482 - val_loss: 1.4165 - val_accuracy: 0.4525\n",
      "Epoch 195/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.1530 - accuracy: 0.5683 - val_loss: 1.4282 - val_accuracy: 0.4402\n",
      "Epoch 196/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.0625 - accuracy: 0.5920 - val_loss: 1.4198 - val_accuracy: 0.4540\n",
      "Epoch 197/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.1249 - accuracy: 0.5669 - val_loss: 1.4933 - val_accuracy: 0.4218\n",
      "Epoch 198/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1545 - accuracy: 0.5605 - val_loss: 1.4185 - val_accuracy: 0.4387\n",
      "Epoch 199/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1105 - accuracy: 0.5739 - val_loss: 1.4180 - val_accuracy: 0.4433\n",
      "Epoch 200/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1122 - accuracy: 0.5766 - val_loss: 1.4200 - val_accuracy: 0.4294\n",
      "Epoch 201/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 1.0853 - accuracy: 0.5814 - val_loss: 1.4178 - val_accuracy: 0.4494\n",
      "Epoch 202/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0883 - accuracy: 0.5816 - val_loss: 1.4417 - val_accuracy: 0.4525\n",
      "Epoch 203/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.1092 - accuracy: 0.5852 - val_loss: 1.4212 - val_accuracy: 0.4387\n",
      "Epoch 204/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.0641 - accuracy: 0.5911 - val_loss: 1.4163 - val_accuracy: 0.4494\n",
      "Epoch 205/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.1181 - accuracy: 0.5642 - val_loss: 1.4117 - val_accuracy: 0.44331227 - ac\n",
      "Epoch 206/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.1036 - accuracy: 0.5724 - val_loss: 1.4117 - val_accuracy: 0.4540\n",
      "Epoch 207/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.0739 - accuracy: 0.6031 - val_loss: 1.4159 - val_accuracy: 0.4433\n",
      "Epoch 208/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0932 - accuracy: 0.5906 - val_loss: 1.4223 - val_accuracy: 0.4433\n",
      "Epoch 209/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.0779 - accuracy: 0.5851 - val_loss: 1.4232 - val_accuracy: 0.4356\n",
      "Epoch 210/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.0974 - accuracy: 0.5700 - val_loss: 1.4170 - val_accuracy: 0.4433\n",
      "Epoch 211/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.0618 - accuracy: 0.6100 - val_loss: 1.4170 - val_accuracy: 0.4525\n",
      "Epoch 212/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.0790 - accuracy: 0.5813 - val_loss: 1.4154 - val_accuracy: 0.4494\n",
      "Epoch 213/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.0591 - accuracy: 0.6026 - val_loss: 1.4261 - val_accuracy: 0.4571\n",
      "Epoch 214/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.0771 - accuracy: 0.5955 - val_loss: 1.4200 - val_accuracy: 0.4448\n",
      "Epoch 215/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.0833 - accuracy: 0.5892 - val_loss: 1.4548 - val_accuracy: 0.4433\n",
      "Epoch 216/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 1.0444 - accuracy: 0.6102 - val_loss: 1.4288 - val_accuracy: 0.4294\n",
      "Epoch 217/750\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 1.0403 - accuracy: 0.6289 - val_loss: 1.4107 - val_accuracy: 0.4540\n",
      "Epoch 218/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0730 - accuracy: 0.5798 - val_loss: 1.4886 - val_accuracy: 0.4264\n",
      "Epoch 219/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0778 - accuracy: 0.5754 - val_loss: 1.4064 - val_accuracy: 0.4509\n",
      "Epoch 220/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.0484 - accuracy: 0.6134 - val_loss: 1.4068 - val_accuracy: 0.4525\n",
      "Epoch 221/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 1.0395 - accuracy: 0.6127 - val_loss: 1.4058 - val_accuracy: 0.4586\n",
      "Epoch 222/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.0425 - accuracy: 0.5836 - val_loss: 1.4222 - val_accuracy: 0.4417\n",
      "Epoch 223/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.0134 - accuracy: 0.6156 - val_loss: 1.4077 - val_accuracy: 0.4463\n",
      "Epoch 224/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0290 - accuracy: 0.6133 - val_loss: 1.4191 - val_accuracy: 0.4340\n",
      "Epoch 225/750\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 1.0542 - accuracy: 0.5937 - val_loss: 1.4296 - val_accuracy: 0.4433\n",
      "Epoch 226/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9910 - accuracy: 0.6063 - val_loss: 1.4106 - val_accuracy: 0.4371\n",
      "Epoch 227/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0386 - accuracy: 0.6088 - val_loss: 1.4225 - val_accuracy: 0.4571\n",
      "Epoch 228/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.0538 - accuracy: 0.6012 - val_loss: 1.4225 - val_accuracy: 0.4264\n",
      "Epoch 229/750\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 1.0252 - accuracy: 0.6109 - val_loss: 1.4515 - val_accuracy: 0.4402\n",
      "Epoch 230/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0389 - accuracy: 0.6209 - val_loss: 1.4615 - val_accuracy: 0.4417\n",
      "Epoch 231/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0311 - accuracy: 0.6397 - val_loss: 1.4245 - val_accuracy: 0.4402\n",
      "Epoch 232/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 1.0549 - accuracy: 0.6022 - val_loss: 1.4136 - val_accuracy: 0.4617\n",
      "Epoch 233/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0478 - accuracy: 0.6113 - val_loss: 1.4260 - val_accuracy: 0.4540\n",
      "Epoch 234/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0099 - accuracy: 0.6163 - val_loss: 1.4189 - val_accuracy: 0.4617\n",
      "Epoch 235/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 1.0337 - accuracy: 0.5985 - val_loss: 1.4131 - val_accuracy: 0.4448\n",
      "Epoch 236/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 1.0641 - accuracy: 0.5901 - val_loss: 1.4115 - val_accuracy: 0.4448\n",
      "Epoch 237/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.0308 - accuracy: 0.6069 - val_loss: 1.4117 - val_accuracy: 0.4586\n",
      "Epoch 238/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 1.0579 - accuracy: 0.5897 - val_loss: 1.4102 - val_accuracy: 0.4433\n",
      "Epoch 239/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 1.0068 - accuracy: 0.6200 - val_loss: 1.4250 - val_accuracy: 0.4417\n",
      "Epoch 240/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0078 - accuracy: 0.6196 - val_loss: 1.4096 - val_accuracy: 0.4479\n",
      "Epoch 241/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 1.0385 - accuracy: 0.5986 - val_loss: 1.4039 - val_accuracy: 0.4387\n",
      "Epoch 242/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9848 - accuracy: 0.6319 - val_loss: 1.4272 - val_accuracy: 0.4433\n",
      "Epoch 243/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0418 - accuracy: 0.6058 - val_loss: 1.4092 - val_accuracy: 0.4571\n",
      "Epoch 244/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0072 - accuracy: 0.6381 - val_loss: 1.4268 - val_accuracy: 0.4463\n",
      "Epoch 245/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9983 - accuracy: 0.6178 - val_loss: 1.4099 - val_accuracy: 0.4509\n",
      "Epoch 246/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 1.0245 - accuracy: 0.6228 - val_loss: 1.4252 - val_accuracy: 0.4463\n",
      "Epoch 247/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.0076 - accuracy: 0.6109 - val_loss: 1.4341 - val_accuracy: 0.4601\n",
      "Epoch 248/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9686 - accuracy: 0.6462 - val_loss: 1.4173 - val_accuracy: 0.4448\n",
      "Epoch 249/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9811 - accuracy: 0.6458 - val_loss: 1.4629 - val_accuracy: 0.4325\n",
      "Epoch 250/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 1.0261 - accuracy: 0.6131 - val_loss: 1.4056 - val_accuracy: 0.4724\n",
      "Epoch 251/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9975 - accuracy: 0.6369 - val_loss: 1.4147 - val_accuracy: 0.4387\n",
      "Epoch 252/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0015 - accuracy: 0.6104 - val_loss: 1.4107 - val_accuracy: 0.4571\n",
      "Epoch 253/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.9878 - accuracy: 0.6036 - val_loss: 1.4225 - val_accuracy: 0.4509\n",
      "Epoch 254/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9973 - accuracy: 0.6227 - val_loss: 1.4122 - val_accuracy: 0.4433\n",
      "Epoch 255/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9776 - accuracy: 0.6328 - val_loss: 1.4174 - val_accuracy: 0.4525\n",
      "Epoch 256/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9564 - accuracy: 0.6314 - val_loss: 1.4100 - val_accuracy: 0.4601\n",
      "Epoch 257/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9662 - accuracy: 0.6163 - val_loss: 1.4750 - val_accuracy: 0.4463\n",
      "Epoch 258/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9750 - accuracy: 0.6305 - val_loss: 1.4165 - val_accuracy: 0.4463\n",
      "Epoch 259/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9968 - accuracy: 0.6249 - val_loss: 1.4193 - val_accuracy: 0.4448\n",
      "Epoch 260/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 1.0000 - accuracy: 0.6110 - val_loss: 1.4309 - val_accuracy: 0.4463\n",
      "Epoch 261/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9665 - accuracy: 0.6495 - val_loss: 1.4052 - val_accuracy: 0.4647\n",
      "Epoch 262/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9676 - accuracy: 0.6457 - val_loss: 1.4562 - val_accuracy: 0.4555\n",
      "Epoch 263/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9732 - accuracy: 0.6485 - val_loss: 1.4394 - val_accuracy: 0.4525\n",
      "Epoch 264/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9947 - accuracy: 0.6045 - val_loss: 1.4281 - val_accuracy: 0.4571\n",
      "Epoch 265/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9914 - accuracy: 0.6356 - val_loss: 1.4613 - val_accuracy: 0.4693\n",
      "Epoch 266/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 1.0033 - accuracy: 0.6108 - val_loss: 1.4214 - val_accuracy: 0.4525\n",
      "Epoch 267/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9770 - accuracy: 0.6145 - val_loss: 1.4443 - val_accuracy: 0.4571\n",
      "Epoch 268/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9877 - accuracy: 0.6393 - val_loss: 1.4114 - val_accuracy: 0.4617\n",
      "Epoch 269/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9409 - accuracy: 0.6529 - val_loss: 1.4044 - val_accuracy: 0.4663\n",
      "Epoch 270/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9811 - accuracy: 0.6357 - val_loss: 1.4214 - val_accuracy: 0.4540\n",
      "Epoch 271/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9580 - accuracy: 0.6385 - val_loss: 1.4056 - val_accuracy: 0.4770\n",
      "Epoch 272/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9601 - accuracy: 0.6448 - val_loss: 1.4252 - val_accuracy: 0.4586\n",
      "Epoch 273/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9655 - accuracy: 0.6484 - val_loss: 1.4267 - val_accuracy: 0.4402\n",
      "Epoch 274/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.9499 - accuracy: 0.6599 - val_loss: 1.4158 - val_accuracy: 0.4755\n",
      "Epoch 275/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9641 - accuracy: 0.6448 - val_loss: 1.4122 - val_accuracy: 0.4509\n",
      "Epoch 276/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9298 - accuracy: 0.6329 - val_loss: 1.4149 - val_accuracy: 0.4509\n",
      "Epoch 277/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.9699 - accuracy: 0.6483 - val_loss: 1.4125 - val_accuracy: 0.4555\n",
      "Epoch 278/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9529 - accuracy: 0.6374 - val_loss: 1.4280 - val_accuracy: 0.4494\n",
      "Epoch 279/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9398 - accuracy: 0.6519 - val_loss: 1.4125 - val_accuracy: 0.4617\n",
      "Epoch 280/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9253 - accuracy: 0.6639 - val_loss: 1.4137 - val_accuracy: 0.4785\n",
      "Epoch 281/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9454 - accuracy: 0.6417 - val_loss: 1.4115 - val_accuracy: 0.4617\n",
      "Epoch 282/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9564 - accuracy: 0.6300 - val_loss: 1.4078 - val_accuracy: 0.4678\n",
      "Epoch 283/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9541 - accuracy: 0.6446 - val_loss: 1.4305 - val_accuracy: 0.4632\n",
      "Epoch 284/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9356 - accuracy: 0.6479 - val_loss: 1.4923 - val_accuracy: 0.4279\n",
      "Epoch 285/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9473 - accuracy: 0.6438 - val_loss: 1.4075 - val_accuracy: 0.4755\n",
      "Epoch 286/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.9519 - accuracy: 0.6430 - val_loss: 1.4209 - val_accuracy: 0.4617\n",
      "Epoch 287/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.9263 - accuracy: 0.6561 - val_loss: 1.4125 - val_accuracy: 0.4709\n",
      "Epoch 288/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9768 - accuracy: 0.6336 - val_loss: 1.4114 - val_accuracy: 0.4540\n",
      "Epoch 289/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9306 - accuracy: 0.6427 - val_loss: 1.4058 - val_accuracy: 0.4693\n",
      "Epoch 290/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.9656 - accuracy: 0.6576 - val_loss: 1.4115 - val_accuracy: 0.4433\n",
      "Epoch 291/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9564 - accuracy: 0.6250 - val_loss: 1.4219 - val_accuracy: 0.4709\n",
      "Epoch 292/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9385 - accuracy: 0.6442 - val_loss: 1.4199 - val_accuracy: 0.4678\n",
      "Epoch 293/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.9337 - accuracy: 0.6371 - val_loss: 1.4365 - val_accuracy: 0.4448\n",
      "Epoch 294/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.9402 - accuracy: 0.6504 - val_loss: 1.4184 - val_accuracy: 0.4617\n",
      "Epoch 295/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8945 - accuracy: 0.6563 - val_loss: 1.4114 - val_accuracy: 0.4939\n",
      "Epoch 296/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.8888 - accuracy: 0.6579 - val_loss: 1.4171 - val_accuracy: 0.4525\n",
      "Epoch 297/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.9493 - accuracy: 0.6390 - val_loss: 1.4170 - val_accuracy: 0.4555\n",
      "Epoch 298/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9024 - accuracy: 0.6782 - val_loss: 1.4277 - val_accuracy: 0.4632\n",
      "Epoch 299/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.9099 - accuracy: 0.6433 - val_loss: 1.4340 - val_accuracy: 0.4494\n",
      "Epoch 300/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8813 - accuracy: 0.6677 - val_loss: 1.4050 - val_accuracy: 0.4739\n",
      "Epoch 301/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.9085 - accuracy: 0.6549 - val_loss: 1.4454 - val_accuracy: 0.4371\n",
      "Epoch 302/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8829 - accuracy: 0.6782 - val_loss: 1.4193 - val_accuracy: 0.4509\n",
      "Epoch 303/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8954 - accuracy: 0.6538 - val_loss: 1.4182 - val_accuracy: 0.4693\n",
      "Epoch 304/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8958 - accuracy: 0.6714 - val_loss: 1.4152 - val_accuracy: 0.4693\n",
      "Epoch 305/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.9224 - accuracy: 0.6699 - val_loss: 1.4125 - val_accuracy: 0.4663\n",
      "Epoch 306/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.9313 - accuracy: 0.6388 - val_loss: 1.4086 - val_accuracy: 0.4632\n",
      "Epoch 307/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8428 - accuracy: 0.6802 - val_loss: 1.4230 - val_accuracy: 0.4555\n",
      "Epoch 308/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.8821 - accuracy: 0.6724 - val_loss: 1.4413 - val_accuracy: 0.4540\n",
      "Epoch 309/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.9187 - accuracy: 0.6432 - val_loss: 1.4123 - val_accuracy: 0.4540\n",
      "Epoch 310/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8911 - accuracy: 0.6541 - val_loss: 1.4291 - val_accuracy: 0.4617\n",
      "Epoch 311/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.9089 - accuracy: 0.6576 - val_loss: 1.4241 - val_accuracy: 0.4678\n",
      "Epoch 312/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8898 - accuracy: 0.6709 - val_loss: 1.4589 - val_accuracy: 0.4586\n",
      "Epoch 313/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.8756 - accuracy: 0.6879 - val_loss: 1.4142 - val_accuracy: 0.4586\n",
      "Epoch 314/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8659 - accuracy: 0.6764 - val_loss: 1.4097 - val_accuracy: 0.4709\n",
      "Epoch 315/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.8570 - accuracy: 0.6887 - val_loss: 1.4431 - val_accuracy: 0.4571\n",
      "Epoch 316/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8860 - accuracy: 0.6804 - val_loss: 1.4244 - val_accuracy: 0.4632\n",
      "Epoch 317/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8689 - accuracy: 0.6951 - val_loss: 1.4087 - val_accuracy: 0.4601\n",
      "Epoch 318/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8551 - accuracy: 0.6809 - val_loss: 1.4096 - val_accuracy: 0.4801\n",
      "Epoch 319/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8782 - accuracy: 0.6585 - val_loss: 1.4300 - val_accuracy: 0.4663\n",
      "Epoch 320/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8905 - accuracy: 0.6722 - val_loss: 1.4267 - val_accuracy: 0.4755\n",
      "Epoch 321/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8993 - accuracy: 0.6655 - val_loss: 1.4185 - val_accuracy: 0.4632\n",
      "Epoch 322/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.8766 - accuracy: 0.6869 - val_loss: 1.4260 - val_accuracy: 0.4571\n",
      "Epoch 323/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8871 - accuracy: 0.6601 - val_loss: 1.4119 - val_accuracy: 0.4739\n",
      "Epoch 324/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8583 - accuracy: 0.6909 - val_loss: 1.4298 - val_accuracy: 0.4586\n",
      "Epoch 325/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8603 - accuracy: 0.6860 - val_loss: 1.4345 - val_accuracy: 0.4479\n",
      "Epoch 326/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8201 - accuracy: 0.7120 - val_loss: 1.4389 - val_accuracy: 0.4601\n",
      "Epoch 327/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.8619 - accuracy: 0.6948 - val_loss: 1.4241 - val_accuracy: 0.4709\n",
      "Epoch 328/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8511 - accuracy: 0.6940 - val_loss: 1.4104 - val_accuracy: 0.4586\n",
      "Epoch 329/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.8482 - accuracy: 0.6918 - val_loss: 1.4276 - val_accuracy: 0.4586\n",
      "Epoch 330/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8403 - accuracy: 0.6936 - val_loss: 1.4175 - val_accuracy: 0.4509\n",
      "Epoch 331/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8843 - accuracy: 0.6790 - val_loss: 1.4403 - val_accuracy: 0.4525\n",
      "Epoch 332/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8376 - accuracy: 0.6974 - val_loss: 1.4132 - val_accuracy: 0.4831\n",
      "Epoch 333/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8654 - accuracy: 0.6873 - val_loss: 1.4257 - val_accuracy: 0.4709\n",
      "Epoch 334/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8479 - accuracy: 0.6986 - val_loss: 1.4843 - val_accuracy: 0.4463\n",
      "Epoch 335/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.8888 - accuracy: 0.6761 - val_loss: 1.4138 - val_accuracy: 0.4724\n",
      "Epoch 336/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.8824 - accuracy: 0.6780 - val_loss: 1.4226 - val_accuracy: 0.4525\n",
      "Epoch 337/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8658 - accuracy: 0.6700 - val_loss: 1.4145 - val_accuracy: 0.4540\n",
      "Epoch 338/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8270 - accuracy: 0.6915 - val_loss: 1.4230 - val_accuracy: 0.4709\n",
      "Epoch 339/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8604 - accuracy: 0.6834 - val_loss: 1.4394 - val_accuracy: 0.4586\n",
      "Epoch 340/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8193 - accuracy: 0.6916 - val_loss: 1.4198 - val_accuracy: 0.4617\n",
      "Epoch 341/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.8464 - accuracy: 0.6720 - val_loss: 1.4223 - val_accuracy: 0.4632\n",
      "Epoch 342/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8379 - accuracy: 0.6995 - val_loss: 1.4354 - val_accuracy: 0.4617\n",
      "Epoch 343/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8620 - accuracy: 0.6870 - val_loss: 1.4364 - val_accuracy: 0.4555\n",
      "Epoch 344/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8597 - accuracy: 0.6843 - val_loss: 1.4958 - val_accuracy: 0.4325\n",
      "Epoch 345/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8390 - accuracy: 0.6991 - val_loss: 1.4186 - val_accuracy: 0.4770\n",
      "Epoch 346/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8341 - accuracy: 0.6988 - val_loss: 1.4299 - val_accuracy: 0.4709\n",
      "Epoch 347/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.8641 - accuracy: 0.6822 - val_loss: 1.4354 - val_accuracy: 0.4693\n",
      "Epoch 348/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8259 - accuracy: 0.7007 - val_loss: 1.4413 - val_accuracy: 0.4540\n",
      "Epoch 349/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7770 - accuracy: 0.7020 - val_loss: 1.4416 - val_accuracy: 0.4632\n",
      "Epoch 350/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8139 - accuracy: 0.7008 - val_loss: 1.4525 - val_accuracy: 0.4509\n",
      "Epoch 351/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8521 - accuracy: 0.6904 - val_loss: 1.4227 - val_accuracy: 0.4739\n",
      "Epoch 352/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.8080 - accuracy: 0.7029 - val_loss: 1.4197 - val_accuracy: 0.4525\n",
      "Epoch 353/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8265 - accuracy: 0.7022 - val_loss: 1.4448 - val_accuracy: 0.4555\n",
      "Epoch 354/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8449 - accuracy: 0.6840 - val_loss: 1.4527 - val_accuracy: 0.4463\n",
      "Epoch 355/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8367 - accuracy: 0.6953 - val_loss: 1.4231 - val_accuracy: 0.4678\n",
      "Epoch 356/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8240 - accuracy: 0.7001 - val_loss: 1.4396 - val_accuracy: 0.4693\n",
      "Epoch 357/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.8042 - accuracy: 0.7060 - val_loss: 1.4256 - val_accuracy: 0.4617\n",
      "Epoch 358/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8179 - accuracy: 0.7004 - val_loss: 1.4518 - val_accuracy: 0.4647\n",
      "Epoch 359/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.8160 - accuracy: 0.6990 - val_loss: 1.4352 - val_accuracy: 0.4678\n",
      "Epoch 360/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.8259 - accuracy: 0.6757 - val_loss: 1.4619 - val_accuracy: 0.4647\n",
      "Epoch 361/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7850 - accuracy: 0.7128 - val_loss: 1.4346 - val_accuracy: 0.4571\n",
      "Epoch 362/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.7671 - accuracy: 0.7321 - val_loss: 1.4527 - val_accuracy: 0.4632\n",
      "Epoch 363/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.7956 - accuracy: 0.7195 - val_loss: 1.4325 - val_accuracy: 0.4632\n",
      "Epoch 364/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8025 - accuracy: 0.7069 - val_loss: 1.4309 - val_accuracy: 0.4663\n",
      "Epoch 365/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7995 - accuracy: 0.7070 - val_loss: 1.4344 - val_accuracy: 0.4555\n",
      "Epoch 366/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7747 - accuracy: 0.7042 - val_loss: 1.4320 - val_accuracy: 0.4724\n",
      "Epoch 367/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.7669 - accuracy: 0.7284 - val_loss: 1.4438 - val_accuracy: 0.4617\n",
      "Epoch 368/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.8054 - accuracy: 0.7164 - val_loss: 1.4403 - val_accuracy: 0.4601\n",
      "Epoch 369/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7720 - accuracy: 0.7300 - val_loss: 1.4543 - val_accuracy: 0.4601\n",
      "Epoch 370/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.8328 - accuracy: 0.6912 - val_loss: 1.4306 - val_accuracy: 0.4678\n",
      "Epoch 371/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7785 - accuracy: 0.7071 - val_loss: 1.4493 - val_accuracy: 0.4617\n",
      "Epoch 372/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.7933 - accuracy: 0.7061 - val_loss: 1.4471 - val_accuracy: 0.4647\n",
      "Epoch 373/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.8032 - accuracy: 0.7026 - val_loss: 1.4295 - val_accuracy: 0.4601\n",
      "Epoch 374/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.8006 - accuracy: 0.6962 - val_loss: 1.4695 - val_accuracy: 0.4601\n",
      "Epoch 375/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.8029 - accuracy: 0.7110 - val_loss: 1.4557 - val_accuracy: 0.4601\n",
      "Epoch 376/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7868 - accuracy: 0.6997 - val_loss: 1.4485 - val_accuracy: 0.4525\n",
      "Epoch 377/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7463 - accuracy: 0.7177 - val_loss: 1.4497 - val_accuracy: 0.4693\n",
      "Epoch 378/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8120 - accuracy: 0.6927 - val_loss: 1.4357 - val_accuracy: 0.4601\n",
      "Epoch 379/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7892 - accuracy: 0.6972 - val_loss: 1.4520 - val_accuracy: 0.4770\n",
      "Epoch 380/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7465 - accuracy: 0.7237 - val_loss: 1.4285 - val_accuracy: 0.4632\n",
      "Epoch 381/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7526 - accuracy: 0.7232 - val_loss: 1.4491 - val_accuracy: 0.4663\n",
      "Epoch 382/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7451 - accuracy: 0.7380 - val_loss: 1.4822 - val_accuracy: 0.4617\n",
      "Epoch 383/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.7758 - accuracy: 0.7273 - val_loss: 1.4419 - val_accuracy: 0.4509\n",
      "Epoch 384/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7819 - accuracy: 0.7171 - val_loss: 1.4460 - val_accuracy: 0.4678\n",
      "Epoch 385/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7783 - accuracy: 0.7249 - val_loss: 1.4378 - val_accuracy: 0.4663\n",
      "Epoch 386/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7856 - accuracy: 0.7281 - val_loss: 1.4397 - val_accuracy: 0.4739\n",
      "Epoch 387/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7674 - accuracy: 0.7106 - val_loss: 1.4431 - val_accuracy: 0.4571\n",
      "Epoch 388/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7707 - accuracy: 0.7164 - val_loss: 1.4425 - val_accuracy: 0.4571\n",
      "Epoch 389/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7617 - accuracy: 0.7263 - val_loss: 1.4464 - val_accuracy: 0.4678\n",
      "Epoch 390/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7611 - accuracy: 0.7355 - val_loss: 1.4550 - val_accuracy: 0.4709\n",
      "Epoch 391/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7658 - accuracy: 0.7074 - val_loss: 1.4566 - val_accuracy: 0.4693\n",
      "Epoch 392/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7863 - accuracy: 0.7190 - val_loss: 1.4484 - val_accuracy: 0.4693\n",
      "Epoch 393/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.7826 - accuracy: 0.7251 - val_loss: 1.4670 - val_accuracy: 0.4693\n",
      "Epoch 394/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7794 - accuracy: 0.7091 - val_loss: 1.4405 - val_accuracy: 0.4709\n",
      "Epoch 395/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7468 - accuracy: 0.7338 - val_loss: 1.4503 - val_accuracy: 0.4693\n",
      "Epoch 396/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7787 - accuracy: 0.7029 - val_loss: 1.4958 - val_accuracy: 0.4463\n",
      "Epoch 397/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7549 - accuracy: 0.7402 - val_loss: 1.4656 - val_accuracy: 0.4617\n",
      "Epoch 398/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7769 - accuracy: 0.7213 - val_loss: 1.4543 - val_accuracy: 0.4755\n",
      "Epoch 399/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7821 - accuracy: 0.7252 - val_loss: 1.4490 - val_accuracy: 0.4709\n",
      "Epoch 400/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7529 - accuracy: 0.7394 - val_loss: 1.4717 - val_accuracy: 0.4647\n",
      "Epoch 401/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.7390 - accuracy: 0.7286 - val_loss: 1.4455 - val_accuracy: 0.4693\n",
      "Epoch 402/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7487 - accuracy: 0.7288 - val_loss: 1.4702 - val_accuracy: 0.4663\n",
      "Epoch 403/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7435 - accuracy: 0.7412 - val_loss: 1.4506 - val_accuracy: 0.4555\n",
      "Epoch 404/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7323 - accuracy: 0.7356 - val_loss: 1.4694 - val_accuracy: 0.4571\n",
      "Epoch 405/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7328 - accuracy: 0.7270 - val_loss: 1.4497 - val_accuracy: 0.4709\n",
      "Epoch 406/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7529 - accuracy: 0.7193 - val_loss: 1.4528 - val_accuracy: 0.4693\n",
      "Epoch 407/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7392 - accuracy: 0.7337 - val_loss: 1.4571 - val_accuracy: 0.4586\n",
      "Epoch 408/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7576 - accuracy: 0.7225 - val_loss: 1.4864 - val_accuracy: 0.4601\n",
      "Epoch 409/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7390 - accuracy: 0.7335 - val_loss: 1.4602 - val_accuracy: 0.4724\n",
      "Epoch 410/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7353 - accuracy: 0.7359 - val_loss: 1.4528 - val_accuracy: 0.4601\n",
      "Epoch 411/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7134 - accuracy: 0.7320 - val_loss: 1.4580 - val_accuracy: 0.4617\n",
      "Epoch 412/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.7220 - accuracy: 0.7455 - val_loss: 1.4845 - val_accuracy: 0.4540\n",
      "Epoch 413/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7485 - accuracy: 0.7205 - val_loss: 1.4592 - val_accuracy: 0.4632\n",
      "Epoch 414/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7391 - accuracy: 0.7312 - val_loss: 1.4624 - val_accuracy: 0.4632\n",
      "Epoch 415/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7730 - accuracy: 0.7097 - val_loss: 1.4603 - val_accuracy: 0.4647\n",
      "Epoch 416/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7020 - accuracy: 0.7560 - val_loss: 1.4676 - val_accuracy: 0.4678\n",
      "Epoch 417/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.6994 - accuracy: 0.7627 - val_loss: 1.5132 - val_accuracy: 0.4571\n",
      "Epoch 418/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7065 - accuracy: 0.7392 - val_loss: 1.4840 - val_accuracy: 0.4632\n",
      "Epoch 419/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7031 - accuracy: 0.7338 - val_loss: 1.4629 - val_accuracy: 0.4663\n",
      "Epoch 420/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7259 - accuracy: 0.7402 - val_loss: 1.4661 - val_accuracy: 0.4647\n",
      "Epoch 421/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7546 - accuracy: 0.7284 - val_loss: 1.4651 - val_accuracy: 0.4555\n",
      "Epoch 422/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.7145 - accuracy: 0.7254 - val_loss: 1.4997 - val_accuracy: 0.4525\n",
      "Epoch 423/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7315 - accuracy: 0.7311 - val_loss: 1.4808 - val_accuracy: 0.4601\n",
      "Epoch 424/750\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 0.7255 - accuracy: 0.7433 - val_loss: 1.4660 - val_accuracy: 0.4678\n",
      "Epoch 425/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7074 - accuracy: 0.7442 - val_loss: 1.4766 - val_accuracy: 0.4632\n",
      "Epoch 426/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7042 - accuracy: 0.7443 - val_loss: 1.4968 - val_accuracy: 0.4617\n",
      "Epoch 427/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7192 - accuracy: 0.7502 - val_loss: 1.5020 - val_accuracy: 0.4525\n",
      "Epoch 428/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7281 - accuracy: 0.7354 - val_loss: 1.4619 - val_accuracy: 0.4494\n",
      "Epoch 429/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7074 - accuracy: 0.7451 - val_loss: 1.4911 - val_accuracy: 0.4586\n",
      "Epoch 430/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6819 - accuracy: 0.7534 - val_loss: 1.4640 - val_accuracy: 0.4647\n",
      "Epoch 431/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.6961 - accuracy: 0.7653 - val_loss: 1.4702 - val_accuracy: 0.4663\n",
      "Epoch 432/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.7243 - accuracy: 0.7526 - val_loss: 1.4640 - val_accuracy: 0.4693\n",
      "Epoch 433/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6852 - accuracy: 0.7511 - val_loss: 1.5227 - val_accuracy: 0.4555\n",
      "Epoch 434/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.7097 - accuracy: 0.7506 - val_loss: 1.4789 - val_accuracy: 0.4663\n",
      "Epoch 435/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.6873 - accuracy: 0.7626 - val_loss: 1.4606 - val_accuracy: 0.4647\n",
      "Epoch 436/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7074 - accuracy: 0.7370 - val_loss: 1.4881 - val_accuracy: 0.4663\n",
      "Epoch 437/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6961 - accuracy: 0.7524 - val_loss: 1.4794 - val_accuracy: 0.4601\n",
      "Epoch 438/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7008 - accuracy: 0.7571 - val_loss: 1.4787 - val_accuracy: 0.4601\n",
      "Epoch 439/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6938 - accuracy: 0.7516 - val_loss: 1.4629 - val_accuracy: 0.4663\n",
      "Epoch 440/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6984 - accuracy: 0.7761 - val_loss: 1.4664 - val_accuracy: 0.4555\n",
      "Epoch 441/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.6803 - accuracy: 0.7504 - val_loss: 1.5113 - val_accuracy: 0.4540\n",
      "Epoch 442/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6539 - accuracy: 0.7728 - val_loss: 1.4799 - val_accuracy: 0.4586\n",
      "Epoch 443/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6745 - accuracy: 0.7566 - val_loss: 1.4886 - val_accuracy: 0.4739\n",
      "Epoch 444/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7328 - accuracy: 0.7290 - val_loss: 1.4731 - val_accuracy: 0.4632\n",
      "Epoch 445/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.7204 - accuracy: 0.7561 - val_loss: 1.4925 - val_accuracy: 0.4601\n",
      "Epoch 446/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6926 - accuracy: 0.7435 - val_loss: 1.4969 - val_accuracy: 0.4601\n",
      "Epoch 447/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6642 - accuracy: 0.7598 - val_loss: 1.5007 - val_accuracy: 0.4724\n",
      "Epoch 448/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6751 - accuracy: 0.7692 - val_loss: 1.4827 - val_accuracy: 0.4509\n",
      "Epoch 449/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6252 - accuracy: 0.7865 - val_loss: 1.5048 - val_accuracy: 0.4571\n",
      "Epoch 450/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.7103 - accuracy: 0.7410 - val_loss: 1.4878 - val_accuracy: 0.4433\n",
      "Epoch 451/750\n",
      "46/46 [==============================] - 4s 78ms/step - loss: 0.7184 - accuracy: 0.7465 - val_loss: 1.4893 - val_accuracy: 0.4709\n",
      "Epoch 452/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.6724 - accuracy: 0.7513 - val_loss: 1.5295 - val_accuracy: 0.4525\n",
      "Epoch 453/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6677 - accuracy: 0.7520 - val_loss: 1.5164 - val_accuracy: 0.4555\n",
      "Epoch 454/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6635 - accuracy: 0.7570 - val_loss: 1.5261 - val_accuracy: 0.4617\n",
      "Epoch 455/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6440 - accuracy: 0.7783 - val_loss: 1.4785 - val_accuracy: 0.4571\n",
      "Epoch 456/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6663 - accuracy: 0.7687 - val_loss: 1.4809 - val_accuracy: 0.4494\n",
      "Epoch 457/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6531 - accuracy: 0.7590 - val_loss: 1.5160 - val_accuracy: 0.4525\n",
      "Epoch 458/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6467 - accuracy: 0.7677 - val_loss: 1.5252 - val_accuracy: 0.4601\n",
      "Epoch 459/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6609 - accuracy: 0.7875 - val_loss: 1.5010 - val_accuracy: 0.4617\n",
      "Epoch 460/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6709 - accuracy: 0.7570 - val_loss: 1.5124 - val_accuracy: 0.4647\n",
      "Epoch 461/750\n",
      "46/46 [==============================] - 4s 79ms/step - loss: 0.6683 - accuracy: 0.7572 - val_loss: 1.4976 - val_accuracy: 0.4678\n",
      "Epoch 462/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.6450 - accuracy: 0.7623 - val_loss: 1.4826 - val_accuracy: 0.4632\n",
      "Epoch 463/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6416 - accuracy: 0.7618 - val_loss: 1.4840 - val_accuracy: 0.4617\n",
      "Epoch 464/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6489 - accuracy: 0.7758 - val_loss: 1.5072 - val_accuracy: 0.4601\n",
      "Epoch 465/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6428 - accuracy: 0.7808 - val_loss: 1.5103 - val_accuracy: 0.4601\n",
      "Epoch 466/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.6199 - accuracy: 0.7807 - val_loss: 1.4923 - val_accuracy: 0.4632\n",
      "Epoch 467/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6749 - accuracy: 0.7588 - val_loss: 1.4889 - val_accuracy: 0.4678\n",
      "Epoch 468/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6849 - accuracy: 0.7600 - val_loss: 1.4922 - val_accuracy: 0.4571\n",
      "Epoch 469/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6595 - accuracy: 0.7674 - val_loss: 1.5184 - val_accuracy: 0.4433\n",
      "Epoch 470/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.6711 - accuracy: 0.7545 - val_loss: 1.4827 - val_accuracy: 0.4678\n",
      "Epoch 471/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.6596 - accuracy: 0.7695 - val_loss: 1.4923 - val_accuracy: 0.4647\n",
      "Epoch 472/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6424 - accuracy: 0.7544 - val_loss: 1.5189 - val_accuracy: 0.4586\n",
      "Epoch 473/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6539 - accuracy: 0.7623 - val_loss: 1.5198 - val_accuracy: 0.4709\n",
      "Epoch 474/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6467 - accuracy: 0.7521 - val_loss: 1.4936 - val_accuracy: 0.4540\n",
      "Epoch 475/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6243 - accuracy: 0.7830 - val_loss: 1.5137 - val_accuracy: 0.4693\n",
      "Epoch 476/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6152 - accuracy: 0.7927 - val_loss: 1.5083 - val_accuracy: 0.4540\n",
      "Epoch 477/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6155 - accuracy: 0.7746 - val_loss: 1.5199 - val_accuracy: 0.4647\n",
      "Epoch 478/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6321 - accuracy: 0.7623 - val_loss: 1.5279 - val_accuracy: 0.4571\n",
      "Epoch 479/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6409 - accuracy: 0.7744 - val_loss: 1.5135 - val_accuracy: 0.4739\n",
      "Epoch 480/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6525 - accuracy: 0.7730 - val_loss: 1.5184 - val_accuracy: 0.4540\n",
      "Epoch 481/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.6286 - accuracy: 0.7957 - val_loss: 1.5049 - val_accuracy: 0.4509\n",
      "Epoch 482/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.6276 - accuracy: 0.7862 - val_loss: 1.5104 - val_accuracy: 0.4586\n",
      "Epoch 483/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6579 - accuracy: 0.7754 - val_loss: 1.5008 - val_accuracy: 0.4555\n",
      "Epoch 484/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6238 - accuracy: 0.7726 - val_loss: 1.4970 - val_accuracy: 0.4586\n",
      "Epoch 485/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6291 - accuracy: 0.7757 - val_loss: 1.5393 - val_accuracy: 0.4601\n",
      "Epoch 486/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6347 - accuracy: 0.7784 - val_loss: 1.5366 - val_accuracy: 0.4601\n",
      "Epoch 487/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.5974 - accuracy: 0.7816 - val_loss: 1.5085 - val_accuracy: 0.4724\n",
      "Epoch 488/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6347 - accuracy: 0.7772 - val_loss: 1.5402 - val_accuracy: 0.4571\n",
      "Epoch 489/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.6415 - accuracy: 0.7780 - val_loss: 1.5610 - val_accuracy: 0.4525\n",
      "Epoch 490/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.6198 - accuracy: 0.7716 - val_loss: 1.5095 - val_accuracy: 0.4571\n",
      "Epoch 491/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6190 - accuracy: 0.7689 - val_loss: 1.5113 - val_accuracy: 0.4601\n",
      "Epoch 492/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6101 - accuracy: 0.7803 - val_loss: 1.5350 - val_accuracy: 0.4632\n",
      "Epoch 493/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6563 - accuracy: 0.7691 - val_loss: 1.5445 - val_accuracy: 0.4632\n",
      "Epoch 494/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6129 - accuracy: 0.8003 - val_loss: 1.5361 - val_accuracy: 0.4463\n",
      "Epoch 495/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6115 - accuracy: 0.7835 - val_loss: 1.5090 - val_accuracy: 0.4678\n",
      "Epoch 496/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6019 - accuracy: 0.7892 - val_loss: 1.5132 - val_accuracy: 0.4525\n",
      "Epoch 497/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.6232 - accuracy: 0.7796 - val_loss: 1.5166 - val_accuracy: 0.4647\n",
      "Epoch 498/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5846 - accuracy: 0.7869 - val_loss: 1.5346 - val_accuracy: 0.4571\n",
      "Epoch 499/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.6430 - accuracy: 0.7639 - val_loss: 1.5184 - val_accuracy: 0.4525\n",
      "Epoch 500/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.6129 - accuracy: 0.7950 - val_loss: 1.5555 - val_accuracy: 0.4586\n",
      "Epoch 501/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6255 - accuracy: 0.7605 - val_loss: 1.5234 - val_accuracy: 0.4509\n",
      "Epoch 502/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6141 - accuracy: 0.7709 - val_loss: 1.5869 - val_accuracy: 0.4617\n",
      "Epoch 503/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5945 - accuracy: 0.7884 - val_loss: 1.5385 - val_accuracy: 0.4586\n",
      "Epoch 504/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.5893 - accuracy: 0.8046 - val_loss: 1.5355 - val_accuracy: 0.4663\n",
      "Epoch 505/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5784 - accuracy: 0.7850 - val_loss: 1.5629 - val_accuracy: 0.4571\n",
      "Epoch 506/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5769 - accuracy: 0.7981 - val_loss: 1.5999 - val_accuracy: 0.4463\n",
      "Epoch 507/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.6041 - accuracy: 0.7839 - val_loss: 1.5378 - val_accuracy: 0.4586\n",
      "Epoch 508/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.5871 - accuracy: 0.7948 - val_loss: 1.5159 - val_accuracy: 0.4601\n",
      "Epoch 509/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.5981 - accuracy: 0.7904 - val_loss: 1.5153 - val_accuracy: 0.4586\n",
      "Epoch 510/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5521 - accuracy: 0.8043 - val_loss: 1.5419 - val_accuracy: 0.4540\n",
      "Epoch 511/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6185 - accuracy: 0.7771 - val_loss: 1.5320 - val_accuracy: 0.4647\n",
      "Epoch 512/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.5757 - accuracy: 0.8055 - val_loss: 1.5583 - val_accuracy: 0.4525\n",
      "Epoch 513/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6333 - accuracy: 0.7749 - val_loss: 1.5189 - val_accuracy: 0.4617\n",
      "Epoch 514/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5601 - accuracy: 0.7992 - val_loss: 1.5492 - val_accuracy: 0.4509\n",
      "Epoch 515/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5731 - accuracy: 0.7996 - val_loss: 1.5517 - val_accuracy: 0.4494\n",
      "Epoch 516/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5886 - accuracy: 0.7968 - val_loss: 1.5225 - val_accuracy: 0.4647\n",
      "Epoch 517/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5618 - accuracy: 0.8217 - val_loss: 1.5306 - val_accuracy: 0.4494\n",
      "Epoch 518/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.5743 - accuracy: 0.7933 - val_loss: 1.5282 - val_accuracy: 0.4479\n",
      "Epoch 519/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5908 - accuracy: 0.8099 - val_loss: 1.5688 - val_accuracy: 0.4632\n",
      "Epoch 520/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5535 - accuracy: 0.8098 - val_loss: 1.5714 - val_accuracy: 0.4586\n",
      "Epoch 521/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5821 - accuracy: 0.7856 - val_loss: 1.5321 - val_accuracy: 0.4586\n",
      "Epoch 522/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.6016 - accuracy: 0.7998 - val_loss: 1.6172 - val_accuracy: 0.4586\n",
      "Epoch 523/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.6059 - accuracy: 0.7833 - val_loss: 1.5327 - val_accuracy: 0.4555\n",
      "Epoch 524/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5806 - accuracy: 0.8012 - val_loss: 1.5807 - val_accuracy: 0.4601\n",
      "Epoch 525/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5828 - accuracy: 0.7867 - val_loss: 1.5524 - val_accuracy: 0.4571\n",
      "Epoch 526/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5590 - accuracy: 0.8005 - val_loss: 1.5337 - val_accuracy: 0.4586\n",
      "Epoch 527/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5760 - accuracy: 0.7901 - val_loss: 1.5550 - val_accuracy: 0.4647\n",
      "Epoch 528/750\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 0.5632 - accuracy: 0.8010 - val_loss: 1.5637 - val_accuracy: 0.4678\n",
      "Epoch 529/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5754 - accuracy: 0.8050 - val_loss: 1.6203 - val_accuracy: 0.4678\n",
      "Epoch 530/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5171 - accuracy: 0.8171 - val_loss: 1.5714 - val_accuracy: 0.4571\n",
      "Epoch 531/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5640 - accuracy: 0.7956 - val_loss: 1.5530 - val_accuracy: 0.4571\n",
      "Epoch 532/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5515 - accuracy: 0.8184 - val_loss: 1.5396 - val_accuracy: 0.4433\n",
      "Epoch 533/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5275 - accuracy: 0.8301 - val_loss: 1.5370 - val_accuracy: 0.4525\n",
      "Epoch 534/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5746 - accuracy: 0.7948 - val_loss: 1.5213 - val_accuracy: 0.4463\n",
      "Epoch 535/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5618 - accuracy: 0.8034 - val_loss: 1.5772 - val_accuracy: 0.4647\n",
      "Epoch 536/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5555 - accuracy: 0.8017 - val_loss: 1.5656 - val_accuracy: 0.4433\n",
      "Epoch 537/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.5577 - accuracy: 0.8092 - val_loss: 1.5677 - val_accuracy: 0.4617\n",
      "Epoch 538/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.5506 - accuracy: 0.8031 - val_loss: 1.5498 - val_accuracy: 0.4647\n",
      "Epoch 539/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5360 - accuracy: 0.8092 - val_loss: 1.5551 - val_accuracy: 0.4555\n",
      "Epoch 540/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5367 - accuracy: 0.8090 - val_loss: 1.5787 - val_accuracy: 0.4617\n",
      "Epoch 541/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5652 - accuracy: 0.8223 - val_loss: 1.5761 - val_accuracy: 0.4586\n",
      "Epoch 542/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5417 - accuracy: 0.8186 - val_loss: 1.5521 - val_accuracy: 0.4540\n",
      "Epoch 543/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5466 - accuracy: 0.8045 - val_loss: 1.5663 - val_accuracy: 0.4709\n",
      "Epoch 544/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5259 - accuracy: 0.8259 - val_loss: 1.5760 - val_accuracy: 0.4632\n",
      "Epoch 545/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5121 - accuracy: 0.8289 - val_loss: 1.5872 - val_accuracy: 0.4663\n",
      "Epoch 546/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5656 - accuracy: 0.8019 - val_loss: 1.5545 - val_accuracy: 0.4647\n",
      "Epoch 547/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.5400 - accuracy: 0.8265 - val_loss: 1.6268 - val_accuracy: 0.4525\n",
      "Epoch 548/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.5390 - accuracy: 0.8105 - val_loss: 1.5602 - val_accuracy: 0.4555\n",
      "Epoch 549/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5475 - accuracy: 0.7936 - val_loss: 1.5802 - val_accuracy: 0.4632\n",
      "Epoch 550/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5516 - accuracy: 0.8026 - val_loss: 1.5951 - val_accuracy: 0.4632\n",
      "Epoch 551/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5104 - accuracy: 0.8299 - val_loss: 1.5599 - val_accuracy: 0.4540\n",
      "Epoch 552/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5245 - accuracy: 0.8140 - val_loss: 1.5916 - val_accuracy: 0.4571\n",
      "Epoch 553/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5321 - accuracy: 0.8111 - val_loss: 1.5717 - val_accuracy: 0.4402\n",
      "Epoch 554/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5285 - accuracy: 0.8210 - val_loss: 1.5518 - val_accuracy: 0.4555\n",
      "Epoch 555/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5225 - accuracy: 0.8154 - val_loss: 1.5511 - val_accuracy: 0.4494\n",
      "Epoch 556/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5166 - accuracy: 0.8219 - val_loss: 1.6085 - val_accuracy: 0.4663\n",
      "Epoch 557/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5241 - accuracy: 0.8125 - val_loss: 1.5911 - val_accuracy: 0.4663\n",
      "Epoch 558/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.5211 - accuracy: 0.8089 - val_loss: 1.5725 - val_accuracy: 0.4647\n",
      "Epoch 559/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.4941 - accuracy: 0.8398 - val_loss: 1.5729 - val_accuracy: 0.4586\n",
      "Epoch 560/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5216 - accuracy: 0.8139 - val_loss: 1.6295 - val_accuracy: 0.4663\n",
      "Epoch 561/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5376 - accuracy: 0.8023 - val_loss: 1.5845 - val_accuracy: 0.4678\n",
      "Epoch 562/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5566 - accuracy: 0.7941 - val_loss: 1.5859 - val_accuracy: 0.4494\n",
      "Epoch 563/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5012 - accuracy: 0.8199 - val_loss: 1.5679 - val_accuracy: 0.4463\n",
      "Epoch 564/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5040 - accuracy: 0.8292 - val_loss: 1.5687 - val_accuracy: 0.4601\n",
      "Epoch 565/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5147 - accuracy: 0.8165 - val_loss: 1.5732 - val_accuracy: 0.4586\n",
      "Epoch 566/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4908 - accuracy: 0.8431 - val_loss: 1.5742 - val_accuracy: 0.4632\n",
      "Epoch 567/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4990 - accuracy: 0.8420 - val_loss: 1.5865 - val_accuracy: 0.4601\n",
      "Epoch 568/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5083 - accuracy: 0.8417 - val_loss: 1.5812 - val_accuracy: 0.4647\n",
      "Epoch 569/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5106 - accuracy: 0.8264 - val_loss: 1.6369 - val_accuracy: 0.4617\n",
      "Epoch 570/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5132 - accuracy: 0.8405 - val_loss: 1.5911 - val_accuracy: 0.4586\n",
      "Epoch 571/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5082 - accuracy: 0.8295 - val_loss: 1.6129 - val_accuracy: 0.4632\n",
      "Epoch 572/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4924 - accuracy: 0.8278 - val_loss: 1.6019 - val_accuracy: 0.4586\n",
      "Epoch 573/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5132 - accuracy: 0.8429 - val_loss: 1.5899 - val_accuracy: 0.4555\n",
      "Epoch 574/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5176 - accuracy: 0.8109 - val_loss: 1.5883 - val_accuracy: 0.4525\n",
      "Epoch 575/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5018 - accuracy: 0.8299 - val_loss: 1.6037 - val_accuracy: 0.4555\n",
      "Epoch 576/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.5197 - accuracy: 0.8126 - val_loss: 1.6062 - val_accuracy: 0.4525\n",
      "Epoch 577/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.4751 - accuracy: 0.8329 - val_loss: 1.6071 - val_accuracy: 0.4632\n",
      "Epoch 578/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.5074 - accuracy: 0.8294 - val_loss: 1.6077 - val_accuracy: 0.4509\n",
      "Epoch 579/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.5052 - accuracy: 0.8265 - val_loss: 1.6071 - val_accuracy: 0.4647\n",
      "Epoch 580/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.5051 - accuracy: 0.8229 - val_loss: 1.5983 - val_accuracy: 0.4632\n",
      "Epoch 581/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.5195 - accuracy: 0.8077 - val_loss: 1.6154 - val_accuracy: 0.4540\n",
      "Epoch 582/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4888 - accuracy: 0.8321 - val_loss: 1.6123 - val_accuracy: 0.4663\n",
      "Epoch 583/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4673 - accuracy: 0.8579 - val_loss: 1.6051 - val_accuracy: 0.4586\n",
      "Epoch 584/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4913 - accuracy: 0.8303 - val_loss: 1.6230 - val_accuracy: 0.4571\n",
      "Epoch 585/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.5102 - accuracy: 0.8302 - val_loss: 1.6836 - val_accuracy: 0.4601\n",
      "Epoch 586/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.5298 - accuracy: 0.8164 - val_loss: 1.6122 - val_accuracy: 0.4617\n",
      "Epoch 587/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4762 - accuracy: 0.8458 - val_loss: 1.6392 - val_accuracy: 0.4525\n",
      "Epoch 588/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4837 - accuracy: 0.8321 - val_loss: 1.6027 - val_accuracy: 0.4632\n",
      "Epoch 589/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4819 - accuracy: 0.8312 - val_loss: 1.6214 - val_accuracy: 0.4555\n",
      "Epoch 590/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4904 - accuracy: 0.8305 - val_loss: 1.5989 - val_accuracy: 0.4586\n",
      "Epoch 591/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4654 - accuracy: 0.8454 - val_loss: 1.6194 - val_accuracy: 0.4509\n",
      "Epoch 592/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4919 - accuracy: 0.8229 - val_loss: 1.6200 - val_accuracy: 0.4586\n",
      "Epoch 593/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4884 - accuracy: 0.8311 - val_loss: 1.6133 - val_accuracy: 0.4540\n",
      "Epoch 594/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4713 - accuracy: 0.8373 - val_loss: 1.6021 - val_accuracy: 0.4586\n",
      "Epoch 595/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4901 - accuracy: 0.8389 - val_loss: 1.6600 - val_accuracy: 0.4647\n",
      "Epoch 596/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.5049 - accuracy: 0.8345 - val_loss: 1.6112 - val_accuracy: 0.4494\n",
      "Epoch 597/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4638 - accuracy: 0.8549 - val_loss: 1.6852 - val_accuracy: 0.4509\n",
      "Epoch 598/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4753 - accuracy: 0.8444 - val_loss: 1.6414 - val_accuracy: 0.4663\n",
      "Epoch 599/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4603 - accuracy: 0.8569 - val_loss: 1.6417 - val_accuracy: 0.4525\n",
      "Epoch 600/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4434 - accuracy: 0.8643 - val_loss: 1.6174 - val_accuracy: 0.4494\n",
      "Epoch 601/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4482 - accuracy: 0.8564 - val_loss: 1.6212 - val_accuracy: 0.4525\n",
      "Epoch 602/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4415 - accuracy: 0.8488 - val_loss: 1.6053 - val_accuracy: 0.4555\n",
      "Epoch 603/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4863 - accuracy: 0.8308 - val_loss: 1.6778 - val_accuracy: 0.4586\n",
      "Epoch 604/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4573 - accuracy: 0.8484 - val_loss: 1.6214 - val_accuracy: 0.4509\n",
      "Epoch 605/750\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 0.4504 - accuracy: 0.8520 - val_loss: 1.6288 - val_accuracy: 0.4601\n",
      "Epoch 606/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4696 - accuracy: 0.8366 - val_loss: 1.6576 - val_accuracy: 0.4586\n",
      "Epoch 607/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4524 - accuracy: 0.8569 - val_loss: 1.6662 - val_accuracy: 0.4540\n",
      "Epoch 608/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4573 - accuracy: 0.8519 - val_loss: 1.6454 - val_accuracy: 0.4601\n",
      "Epoch 609/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4374 - accuracy: 0.8457 - val_loss: 1.6345 - val_accuracy: 0.4571\n",
      "Epoch 610/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.4371 - accuracy: 0.8679 - val_loss: 1.6475 - val_accuracy: 0.4617\n",
      "Epoch 611/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4568 - accuracy: 0.8368 - val_loss: 1.6160 - val_accuracy: 0.4663\n",
      "Epoch 612/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4381 - accuracy: 0.8500 - val_loss: 1.6273 - val_accuracy: 0.4555\n",
      "Epoch 613/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4471 - accuracy: 0.8579 - val_loss: 1.6518 - val_accuracy: 0.4540\n",
      "Epoch 614/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.4359 - accuracy: 0.8578 - val_loss: 1.6681 - val_accuracy: 0.4586\n",
      "Epoch 615/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.4617 - accuracy: 0.8434 - val_loss: 1.6287 - val_accuracy: 0.4601\n",
      "Epoch 616/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4667 - accuracy: 0.8364 - val_loss: 1.6386 - val_accuracy: 0.4555\n",
      "Epoch 617/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4696 - accuracy: 0.8321 - val_loss: 1.6416 - val_accuracy: 0.4494\n",
      "Epoch 618/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4548 - accuracy: 0.8395 - val_loss: 1.6509 - val_accuracy: 0.4540\n",
      "Epoch 619/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4368 - accuracy: 0.8586 - val_loss: 1.6274 - val_accuracy: 0.4479\n",
      "Epoch 620/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.4104 - accuracy: 0.8640 - val_loss: 1.6499 - val_accuracy: 0.4509\n",
      "Epoch 621/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4215 - accuracy: 0.8569 - val_loss: 1.6437 - val_accuracy: 0.4525\n",
      "Epoch 622/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4162 - accuracy: 0.8659 - val_loss: 1.6842 - val_accuracy: 0.4647\n",
      "Epoch 623/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4098 - accuracy: 0.8626 - val_loss: 1.6337 - val_accuracy: 0.4509\n",
      "Epoch 624/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4132 - accuracy: 0.8736 - val_loss: 1.6871 - val_accuracy: 0.4555\n",
      "Epoch 625/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4541 - accuracy: 0.8538 - val_loss: 1.6629 - val_accuracy: 0.4540\n",
      "Epoch 626/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4520 - accuracy: 0.8462 - val_loss: 1.6455 - val_accuracy: 0.4586\n",
      "Epoch 627/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4462 - accuracy: 0.8468 - val_loss: 1.6869 - val_accuracy: 0.4586\n",
      "Epoch 628/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4430 - accuracy: 0.8468 - val_loss: 1.6392 - val_accuracy: 0.4571\n",
      "Epoch 629/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4160 - accuracy: 0.8593 - val_loss: 1.6627 - val_accuracy: 0.4571\n",
      "Epoch 630/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.3974 - accuracy: 0.8678 - val_loss: 1.6858 - val_accuracy: 0.4601\n",
      "Epoch 631/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.4380 - accuracy: 0.8419 - val_loss: 1.6644 - val_accuracy: 0.4509\n",
      "Epoch 632/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4655 - accuracy: 0.8384 - val_loss: 1.6720 - val_accuracy: 0.4571\n",
      "Epoch 633/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.4607 - accuracy: 0.8461 - val_loss: 1.6476 - val_accuracy: 0.4525\n",
      "Epoch 634/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4165 - accuracy: 0.8530 - val_loss: 1.6589 - val_accuracy: 0.4509\n",
      "Epoch 635/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4262 - accuracy: 0.8534 - val_loss: 1.6676 - val_accuracy: 0.4463\n",
      "Epoch 636/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4394 - accuracy: 0.8433 - val_loss: 1.6933 - val_accuracy: 0.4586\n",
      "Epoch 637/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.4134 - accuracy: 0.8510 - val_loss: 1.6449 - val_accuracy: 0.4632\n",
      "Epoch 638/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.4360 - accuracy: 0.8474 - val_loss: 1.6606 - val_accuracy: 0.4601\n",
      "Epoch 639/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4236 - accuracy: 0.8569 - val_loss: 1.6776 - val_accuracy: 0.4571\n",
      "Epoch 640/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4340 - accuracy: 0.8474 - val_loss: 1.6651 - val_accuracy: 0.4617\n",
      "Epoch 641/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3964 - accuracy: 0.8693 - val_loss: 1.6629 - val_accuracy: 0.4571\n",
      "Epoch 642/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4055 - accuracy: 0.8719 - val_loss: 1.6601 - val_accuracy: 0.4586\n",
      "Epoch 643/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3978 - accuracy: 0.8748 - val_loss: 1.6696 - val_accuracy: 0.4555\n",
      "Epoch 644/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4092 - accuracy: 0.8594 - val_loss: 1.6740 - val_accuracy: 0.4555\n",
      "Epoch 645/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.4172 - accuracy: 0.8631 - val_loss: 1.6591 - val_accuracy: 0.4601\n",
      "Epoch 646/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.4015 - accuracy: 0.8706 - val_loss: 1.6854 - val_accuracy: 0.4555\n",
      "Epoch 647/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4105 - accuracy: 0.8760 - val_loss: 1.6721 - val_accuracy: 0.4555\n",
      "Epoch 648/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3925 - accuracy: 0.8675 - val_loss: 1.6712 - val_accuracy: 0.4555\n",
      "Epoch 649/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.4252 - accuracy: 0.8703 - val_loss: 1.7289 - val_accuracy: 0.4555\n",
      "Epoch 650/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.4185 - accuracy: 0.8520 - val_loss: 1.6693 - val_accuracy: 0.4540\n",
      "Epoch 651/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3863 - accuracy: 0.8810 - val_loss: 1.6853 - val_accuracy: 0.4540\n",
      "Epoch 652/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4218 - accuracy: 0.8672 - val_loss: 1.6869 - val_accuracy: 0.4678\n",
      "Epoch 653/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4099 - accuracy: 0.8584 - val_loss: 1.7298 - val_accuracy: 0.4601\n",
      "Epoch 654/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3893 - accuracy: 0.8630 - val_loss: 1.6905 - val_accuracy: 0.4494\n",
      "Epoch 655/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.4045 - accuracy: 0.8733 - val_loss: 1.7178 - val_accuracy: 0.4555\n",
      "Epoch 656/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.4185 - accuracy: 0.8569 - val_loss: 1.6810 - val_accuracy: 0.4647\n",
      "Epoch 657/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3961 - accuracy: 0.8677 - val_loss: 1.6869 - val_accuracy: 0.4601\n",
      "Epoch 658/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.4084 - accuracy: 0.8608 - val_loss: 1.6848 - val_accuracy: 0.4571\n",
      "Epoch 659/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.4069 - accuracy: 0.8651 - val_loss: 1.6967 - val_accuracy: 0.4678\n",
      "Epoch 660/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.3978 - accuracy: 0.8628 - val_loss: 1.6992 - val_accuracy: 0.4555\n",
      "Epoch 661/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3862 - accuracy: 0.8778 - val_loss: 1.7190 - val_accuracy: 0.4586\n",
      "Epoch 662/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4049 - accuracy: 0.8655 - val_loss: 1.7154 - val_accuracy: 0.4494\n",
      "Epoch 663/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3839 - accuracy: 0.8763 - val_loss: 1.6977 - val_accuracy: 0.4555\n",
      "Epoch 664/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3620 - accuracy: 0.8719 - val_loss: 1.7163 - val_accuracy: 0.4540\n",
      "Epoch 665/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.4023 - accuracy: 0.8523 - val_loss: 1.7065 - val_accuracy: 0.4632\n",
      "Epoch 666/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3702 - accuracy: 0.8851 - val_loss: 1.6960 - val_accuracy: 0.4555\n",
      "Epoch 667/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3753 - accuracy: 0.8721 - val_loss: 1.7413 - val_accuracy: 0.4479\n",
      "Epoch 668/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3711 - accuracy: 0.8831 - val_loss: 1.7359 - val_accuracy: 0.4586\n",
      "Epoch 669/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.3786 - accuracy: 0.8880 - val_loss: 1.7302 - val_accuracy: 0.4632\n",
      "Epoch 670/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.3962 - accuracy: 0.8644 - val_loss: 1.7031 - val_accuracy: 0.4586\n",
      "Epoch 671/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.3667 - accuracy: 0.8833 - val_loss: 1.7028 - val_accuracy: 0.4632\n",
      "Epoch 672/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3767 - accuracy: 0.8939 - val_loss: 1.7279 - val_accuracy: 0.4586\n",
      "Epoch 673/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3703 - accuracy: 0.8836 - val_loss: 1.7169 - val_accuracy: 0.4617\n",
      "Epoch 674/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3568 - accuracy: 0.8837 - val_loss: 1.7301 - val_accuracy: 0.4571\n",
      "Epoch 675/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3720 - accuracy: 0.8876 - val_loss: 1.7626 - val_accuracy: 0.4601\n",
      "Epoch 676/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3724 - accuracy: 0.8686 - val_loss: 1.7390 - val_accuracy: 0.4540\n",
      "Epoch 677/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3655 - accuracy: 0.8852 - val_loss: 1.7297 - val_accuracy: 0.4509\n",
      "Epoch 678/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3739 - accuracy: 0.8775 - val_loss: 1.7153 - val_accuracy: 0.4601\n",
      "Epoch 679/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3907 - accuracy: 0.8697 - val_loss: 1.7199 - val_accuracy: 0.4525\n",
      "Epoch 680/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.3414 - accuracy: 0.8958 - val_loss: 1.7469 - val_accuracy: 0.4632\n",
      "Epoch 681/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3704 - accuracy: 0.8787 - val_loss: 1.7338 - val_accuracy: 0.4647\n",
      "Epoch 682/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.4146 - accuracy: 0.8486 - val_loss: 1.7264 - val_accuracy: 0.4617\n",
      "Epoch 683/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3569 - accuracy: 0.8789 - val_loss: 1.7147 - val_accuracy: 0.4540\n",
      "Epoch 684/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3888 - accuracy: 0.8616 - val_loss: 1.7214 - val_accuracy: 0.4586\n",
      "Epoch 685/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3570 - accuracy: 0.8877 - val_loss: 1.7134 - val_accuracy: 0.4463\n",
      "Epoch 686/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.3916 - accuracy: 0.8679 - val_loss: 1.7487 - val_accuracy: 0.4601\n",
      "Epoch 687/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3585 - accuracy: 0.8909 - val_loss: 1.7471 - val_accuracy: 0.4571\n",
      "Epoch 688/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3823 - accuracy: 0.8745 - val_loss: 1.7364 - val_accuracy: 0.4586\n",
      "Epoch 689/750\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.3958 - accuracy: 0.8627 - val_loss: 1.7251 - val_accuracy: 0.4525\n",
      "Epoch 690/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3563 - accuracy: 0.8765 - val_loss: 1.7506 - val_accuracy: 0.4663\n",
      "Epoch 691/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3865 - accuracy: 0.8650 - val_loss: 1.7482 - val_accuracy: 0.4555\n",
      "Epoch 692/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3573 - accuracy: 0.8796 - val_loss: 1.7726 - val_accuracy: 0.4525\n",
      "Epoch 693/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3563 - accuracy: 0.8867 - val_loss: 1.7415 - val_accuracy: 0.4540\n",
      "Epoch 694/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3430 - accuracy: 0.8815 - val_loss: 1.7433 - val_accuracy: 0.4601\n",
      "Epoch 695/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3680 - accuracy: 0.8772 - val_loss: 1.7449 - val_accuracy: 0.4601\n",
      "Epoch 696/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3386 - accuracy: 0.8952 - val_loss: 1.7587 - val_accuracy: 0.4509\n",
      "Epoch 697/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3859 - accuracy: 0.8729 - val_loss: 1.7850 - val_accuracy: 0.4693\n",
      "Epoch 698/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3427 - accuracy: 0.8859 - val_loss: 1.7778 - val_accuracy: 0.4540\n",
      "Epoch 699/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3658 - accuracy: 0.8701 - val_loss: 1.7703 - val_accuracy: 0.4540\n",
      "Epoch 700/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3433 - accuracy: 0.8877 - val_loss: 1.7415 - val_accuracy: 0.4632\n",
      "Epoch 701/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3356 - accuracy: 0.8975 - val_loss: 1.7430 - val_accuracy: 0.4494\n",
      "Epoch 702/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3533 - accuracy: 0.8799 - val_loss: 1.7807 - val_accuracy: 0.4540\n",
      "Epoch 703/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3265 - accuracy: 0.8814 - val_loss: 1.7389 - val_accuracy: 0.4601\n",
      "Epoch 704/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3232 - accuracy: 0.8963 - val_loss: 1.7703 - val_accuracy: 0.4494\n",
      "Epoch 705/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3474 - accuracy: 0.8827 - val_loss: 1.7908 - val_accuracy: 0.4586\n",
      "Epoch 706/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3246 - accuracy: 0.8863 - val_loss: 1.7409 - val_accuracy: 0.4479\n",
      "Epoch 707/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3249 - accuracy: 0.8993 - val_loss: 1.7451 - val_accuracy: 0.4663\n",
      "Epoch 708/750\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3297 - accuracy: 0.8921 - val_loss: 1.7536 - val_accuracy: 0.4509\n",
      "Epoch 709/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3199 - accuracy: 0.8946 - val_loss: 1.7855 - val_accuracy: 0.4586\n",
      "Epoch 710/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.3199 - accuracy: 0.9080 - val_loss: 1.7796 - val_accuracy: 0.4586\n",
      "Epoch 711/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3368 - accuracy: 0.9007 - val_loss: 1.7838 - val_accuracy: 0.4678\n",
      "Epoch 712/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3259 - accuracy: 0.8961 - val_loss: 1.7634 - val_accuracy: 0.4693\n",
      "Epoch 713/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3378 - accuracy: 0.8916 - val_loss: 1.7560 - val_accuracy: 0.4555\n",
      "Epoch 714/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3377 - accuracy: 0.8904 - val_loss: 1.7672 - val_accuracy: 0.4555\n",
      "Epoch 715/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3618 - accuracy: 0.8937 - val_loss: 1.8060 - val_accuracy: 0.4586\n",
      "Epoch 716/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3405 - accuracy: 0.8970 - val_loss: 1.7710 - val_accuracy: 0.4601\n",
      "Epoch 717/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3254 - accuracy: 0.8977 - val_loss: 1.7941 - val_accuracy: 0.4678\n",
      "Epoch 718/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3110 - accuracy: 0.9077 - val_loss: 1.7832 - val_accuracy: 0.4678\n",
      "Epoch 719/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.3313 - accuracy: 0.8872 - val_loss: 1.7984 - val_accuracy: 0.4448\n",
      "Epoch 720/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3203 - accuracy: 0.9021 - val_loss: 1.7763 - val_accuracy: 0.4540\n",
      "Epoch 721/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3263 - accuracy: 0.8897 - val_loss: 1.8101 - val_accuracy: 0.4540\n",
      "Epoch 722/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3136 - accuracy: 0.9018 - val_loss: 1.8289 - val_accuracy: 0.4525\n",
      "Epoch 723/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3301 - accuracy: 0.8980 - val_loss: 1.7847 - val_accuracy: 0.4586\n",
      "Epoch 724/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3346 - accuracy: 0.8767 - val_loss: 1.8004 - val_accuracy: 0.4617\n",
      "Epoch 725/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.3200 - accuracy: 0.8975 - val_loss: 1.7853 - val_accuracy: 0.4632\n",
      "Epoch 726/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.3055 - accuracy: 0.8930 - val_loss: 1.7849 - val_accuracy: 0.4555\n",
      "Epoch 727/750\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.3417 - accuracy: 0.8848 - val_loss: 1.7880 - val_accuracy: 0.4647\n",
      "Epoch 728/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.2920 - accuracy: 0.9103 - val_loss: 1.8183 - val_accuracy: 0.4494\n",
      "Epoch 729/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3180 - accuracy: 0.8949 - val_loss: 1.8263 - val_accuracy: 0.4509\n",
      "Epoch 730/750\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.2914 - accuracy: 0.9154 - val_loss: 1.8112 - val_accuracy: 0.4509\n",
      "Epoch 731/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.3222 - accuracy: 0.8966 - val_loss: 1.7928 - val_accuracy: 0.4540\n",
      "Epoch 732/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3070 - accuracy: 0.9131 - val_loss: 1.8610 - val_accuracy: 0.4617\n",
      "Epoch 733/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3197 - accuracy: 0.8945 - val_loss: 1.8055 - val_accuracy: 0.4601\n",
      "Epoch 734/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3048 - accuracy: 0.8917 - val_loss: 1.8409 - val_accuracy: 0.4571\n",
      "Epoch 735/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3206 - accuracy: 0.9047 - val_loss: 1.8043 - val_accuracy: 0.4525\n",
      "Epoch 736/750\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.2819 - accuracy: 0.9166 - val_loss: 1.8419 - val_accuracy: 0.4617\n",
      "Epoch 737/750\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.3041 - accuracy: 0.9094 - val_loss: 1.8073 - val_accuracy: 0.4632\n",
      "Epoch 738/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.2951 - accuracy: 0.9079 - val_loss: 1.8312 - val_accuracy: 0.4678\n",
      "Epoch 739/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3017 - accuracy: 0.9019 - val_loss: 1.8124 - val_accuracy: 0.4494\n",
      "Epoch 740/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3208 - accuracy: 0.8973 - val_loss: 1.8272 - val_accuracy: 0.4632\n",
      "Epoch 741/750\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 0.3042 - accuracy: 0.8978 - val_loss: 1.8309 - val_accuracy: 0.4632\n",
      "Epoch 742/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.2789 - accuracy: 0.9255 - val_loss: 1.8378 - val_accuracy: 0.4632\n",
      "Epoch 743/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.2909 - accuracy: 0.9098 - val_loss: 1.8308 - val_accuracy: 0.4540\n",
      "Epoch 744/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3049 - accuracy: 0.9005 - val_loss: 1.8460 - val_accuracy: 0.4525\n",
      "Epoch 745/750\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.2765 - accuracy: 0.9118 - val_loss: 1.8638 - val_accuracy: 0.4525\n",
      "Epoch 746/750\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.3005 - accuracy: 0.9027 - val_loss: 1.8275 - val_accuracy: 0.4632\n",
      "Epoch 747/750\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 0.2972 - accuracy: 0.9002 - val_loss: 1.8466 - val_accuracy: 0.4586\n",
      "Epoch 748/750\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.2970 - accuracy: 0.9035 - val_loss: 1.8472 - val_accuracy: 0.4632\n",
      "Epoch 749/750\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.2911 - accuracy: 0.8997 - val_loss: 1.8748 - val_accuracy: 0.4617\n",
      "Epoch 750/750\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.2981 - accuracy: 0.9034 - val_loss: 1.8690 - val_accuracy: 0.4571\n"
     ]
    }
   ],
   "source": [
    "#Тренировка нейронной сети\n",
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=32, epochs=750, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#График\n",
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\pepega\\saved_models\\SpeechEmotionDetection.h5 \n"
     ]
    }
   ],
   "source": [
    "#Сохранение модели\n",
    "model_name = 'SpeechEmotionDetection.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import keras\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "male_angry\n"
     ]
    }
   ],
   "source": [
    "#Предсказание\n",
    "X, sample_rate = librosa.load('test/male_happy1.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "\n",
    "\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive\n",
    "\n",
    "livedf2= pd.DataFrame(data=livedf2)\n",
    "livedf2 = livedf2.stack().to_frame().T\n",
    "twodim= np.expand_dims(livedf2, axis=2)\n",
    "\n",
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)\n",
    "\n",
    "feelingList = ['female_angry', 'female_calm', 'female_fearful', 'female_happy', 'female_sad', 'male_angry', 'male_calm', 'male_fearful', 'male_happy', 'male_sad']\n",
    "print(feelingList[np.argmax(livepreds)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
